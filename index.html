<!doctype html>
<html lang="en-GB">

	<head>
		<meta charset="utf-8">

		<title>OK Computer - Front End London</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/custom.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Microphone.js -->
		<link rel="stylesheet" href="js/microphone/microphone.min.css" id="theme">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

				<section data-background="images/hal-9000.jpg" data-background-size="cover">
					<h1>OK Computer</h1>
					<h2>Front End London, 29/01/15</h2>
				</section>

				<section>
					<h2>Peter Gasston</h2>
					<h2>@stopsatgreen</h2>
					<h2>broken-links.com</h2>
				</section>

				<section data-background-color="black" data-background-video="images/moon-gerty.mp4"></section>

				<section>
					<h2>Input Types</h2>
					<h3 class="fragment">Touch: Manipulate space</h3>
					<h3 class="fragment">Keyboard: Data entry</h3>
					<h3 class="fragment">Voice: Command or query</h3>

					<aside class="notes">
						Mouse is legacy input and better served by other means in the future - as this clip shows…
					</aside>
				</section>

				<section data-background-color="black" data-background-video="images/startrek-hellocomputer.mp4">
					<aside class="notes">
						We are born to talk. Typing is an impediment in many cases.
					</aside>
				</section>

				<section id="stat1" data-background="images/stroppy-teen.jpg" data-background-size="cover">
					<h1>55% of teens</h1>
					<h1>41% of adults</h1>
					<h3>use voice search every day<span class="fragment">*</span></h3>
					<h4 class="fragment">*maybe</h4>

					<aside class="notes">
						From Google research, but sources not provided. Could be ‘of teens who use, 55% use every day’. http://googleblog.blogspot.co.uk/2014/10/omg-mobile-voice-survey-reveals-teens.html
					</aside>
				</section>

				<section data-background="images/crowdedstreet.jpg" data-background-size="cover">
					<h1>10% of Baidu</h1>
					<h3>search queries are by voice</h3>
					<h2 class="fragment">That’s ~500m per day</h2>

					<aside class="notes">
						Character input is hard, plus high rural illiteracy. http://blogs.wsj.com/digits/2014/11/21/baidus-andrew-ng-on-deep-learning-and-innovation-in-silicon-valley/
						http://iaminchina.wordpress.com/2010/04/13/crowded-street-in-xian/
					</aside>
				</section>

				<section data-background-color="black" data-background-video="images/her-samantha.mp4">
					<h1 class="fragment reverse-text">Synthesis</h1>

					<aside class="notes">
						Long history of replicating voice with sound (Brazen Heads back to ~12th C.) but first systems emerged in 1960s. Bell Labs 1961 sang Daisy Bell, coincidentally Arthur C. Clarke was visiting. Today Stephen Hawking uses system with old voice as it’s ‘his’.
					</aside>
				</section>

				<section id="synthesis1">
					<h2>Chrome/Safari</h2>
					<pre><code data-trim>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt);
window.speechSynthesis.speak(say);
					</code></pre>

					<input class="big" value="Hello Front End London">
					<button class="big">Play</button>
				</section>

				<section id="synthesis2">
					<h3><abbr>SSU</abbr> Attributes</h3>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
    say = new SpeechSynthesisUtterance(txt);
say.lang = 'en-GB';
say.pitch = 0.75;
say.rate = 1.5;
say.volume = 0.5;
window.speechSynthesis.speak(say);
					</code></pre>

					<input class="big" value="Hello F E L" type="text">
					<button class="big">Play</button>
					<input type="range" max="3" min="0" step="0.25" value="1" class="big">

					<aside class="notes">
						Not in Chrome. Show in Safari.
					</aside>
				</section>

				<section>
					<h2>Methods, Attrs, Events</h2>
					<h3>Play / Pause / Resume /<br>Cancel / End / Error</h3>
				</section>

				<section>
					<h2>Synthesis As A Service</h2>
					<ol>
						<li><a href="http://developer.att.com/apis/speech">developer.att.com/apis/speech</a></li>
						<li><a href="https://ws.neospeech.com/">ws.neospeech.com/</a></li>
						<li><a href="https://www.cereproc.com/en/products/cloud">cereproc.com/en/products/cloud</a></li>
						<li><a href="http://www.ivona.com/en/for-business/speech-cloud/">ivona.com/en/for-business/speech-cloud/</a></li>
					</ol>
				</section>

				<section id="neospeech">
					<h2>Neospeech</h2>

					<pre><code data-trim class="break-word" id="neo1"></code></pre>
					<pre><code data-trim class="break-word" id="neo2"></code></pre>

					<input class="big" value="Hello F.E.L.">
					<button class="big" id="neoreq">1</button>
				</section>

				<section>
					<h2>SSML</h2>

					<pre><code data-trim contenteditable>
<speak version="1.0">
<p>
	<s>Hello <abbr>FEL</abbr>.</s>
	<s>This is <prosody rate="-20%">SSML</prosody></s>
</p>
</speak>
					</code></pre>
				</section>

				<section data-background-color="black" data-background-video="images/startrek-library.mp4">
					<h1 class="fragment reverse-text">Recognition</h1>

					<aside class="notes">
						Developed by Bell in 1952. Could recognise numbers spoken by one person. 1970s Carnegie Mellon HARPY could recognise 1,000 words. 1980s Hidden Markov method, chops waves into phonemes and attempts to form words. 2000s improved by deep learning.
					</aside>
				</section>

				<section data-background="images/startrek.jpg" data-background-size="cover">
					<h2>Challenges</h2>
					<ol class="big">
						<li class="fragment">Multiple users</li>
						<li class="fragment">Multiple languages</li>
						<li class="fragment">Accents</li>
					</ol>
				</section>

				<section data-background-color="black" data-background-video="images/siri-scottish.mp4"></section>

				<section>
					<h2>Web Speech API</h2>
					<pre><code data-trim contenteditable>
						var recog = new SpeechRecognition();
					</code></pre>

					<h2 class="fragment">x-browser</h2>
					<pre class="fragment"><code data-trim contenteditable>
var speechRecognition = (
	window.SpeechRecognition ||
	window.webkitSpeechRecognition
);
var recog = new speechRecognition();
					</code></pre>
				</section>

				<section>
					<h3>SpeechRecognition Methods</h3>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.start();
recog.stop();
recog.abort();
					</code></pre>
				</section>

				<section>
					<h3>SpeechRecognition Events</h3>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.onresult = function () {};
recog.onnomatch = function () {};
recog.onerror = function () {};
					</code></pre>
				</section>

				<section id="recognition1">
					<h2 class="trigger"><abbr title="Minimum Viable Script">MVS</abbr></h2>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.onresult = function (result) {
	output.textContent = results[0][0].transcript;
};
btn.onclick = recog.start();
					</code></pre>

					<output class="big"></output>
					<p class="footnote"><i>Click header for demo</i></p>
				</section>

				<section id="recognition2">
					<h3 class="trigger">SpeechRecognition Events</h3>
					<ol id="recog-events">
						<li class="fragment">start</li>
						<li class="fragment">audiostart</li>
						<li class="fragment">soundstart</li>
						<li class="fragment">speechstart</li>
						<li class="fragment">speechend</li>
						<li class="fragment">soundend</li>
						<li class="fragment">audioend</li>
						<li class="fragment">end</li>
					</ol>
					<p class="footnote"><i>Click header for demo</i></p>
				</section>

				<section id="recognition3">
					<h2 class="trigger">Interim Results</h2>
					<pre><code data-trim>
var recog = new SpeechRecognition();
recog.interimResults = true;
					</code></pre>
					<pre class="fragment"><code data-trim>
recog.onresult = function (result) {
	if (result.results[0].isFinal) {…}
};
btn.onclick = recog.start();
					</code></pre>

					<output></output>
					<p class="footnote"><i>Click header for demo</i></p>
				</section>

				<section>
					<h2>Continuous</h2>
					<pre><code data-trim>
var recog = new SpeechRecognition();
recog.continuous = true;
recog.onresult = function (result) {
	output.textContent = result.results[0][0].transcript;
};
					</code></pre>
					<pre class="fragment"><code data-trim>
btn.onclick = function () {
	if (listening) { recog.stop(); }
	else { recog.start(); }
}
					</code></pre>
				</section>

				<section>
					<h2>SpeechRTC +</h2>
					<h2>Web Speech API</h2>

					<aside class="notes">
						Node online, Web Workers offline. https://wiki.mozilla.org/SpeechRTC_-_Speech_enabling_the_open_web
					</aside>
				</section>

				<section>
					<h2><a href="//broken-links.com/teaearlgreyhot">Tea. Earl Grey. Hot.</a></h2>

					<aside class="notes">
						Basically just matching a string / regex. But mobile searches tend to be more conversational, so we need to discover intent.
					</aside>
				</section>

				<section>
					<h2>[Google demo]</h2>
				</section>

				<section>
					<h2>JuliusJS</h2>

					<pre><code data-trim>
var recog = new Julius();
recog.onrecognition = function (result) {
	console.log(result);
}
					</code></pre>
				</section>

				<section data-background="images/api.ai.png" data-background-size="contain"></section>

				<section data-background="images/wit.ai.png" data-background-size="contain"></section>

				<section data-background="images/wit-api.png" data-background-size="contain"></section>

				<section>
					<h1>Wit + Node</h1>
					<ol>
						<li>Web Speech API + text</li>
						<li class="fragment">Direct speech: GuM, Web Audio API</li>
					</ol>

					<aside class="notes"> http://blog.groupbuddies.com/posts/39-tutorial-html-audio-capture-streaming-to-node-js-no-browser-extensions
					</aside>
				</section>

				<section id="wit1">
					<h1>Wit.ai</h1>
					<h2>Microphone.js</h2>
					<div id="mic1" class="microphone"></div>
					<output></output>
				</section>

				<section>
					<h2>[Wit dashboard demo]</h2>
				</section>

				<section id="wit2">
					<h1>Wit.ai</h1>
					<h2>Response</h2>
					<div id="mic2" class="microphone"></div>
				</section>

				<section data-background-color="black" data-background-video="images/2001-hal.mp4"></section>

				<section>
					<h1>Use Cases</h1>
					<h2 class="fragment">No screen</h2>
					<h2 class="fragment">Busy hands</h2>
				</section>

				<section data-background="images/amazon.echo.jpg" data-background-size="contain">
					<h2>Amazon : ‘Alexa’</h2>
					<h2 class="fragment">Apple : Siri</h2>
					<h2 class="fragment">Google : Voice Search</h2>
					<h2 class="fragment">Microsoft : Cortana</h2>
				</section>

				<section data-background-color="black" data-background-video="images/jibo.mp4"></section>

				<section>
					<h1>Closed Systems :(</h1>

					<aside class="notes">
						Would be a disaster if Google only plays Play Music, Apple only iTunes, etc. Make an open system, 3rd-party APIs, no ecosystem lock
					</aside>
				</section>

				<section>
					<h1>The End</h1>
					<h2>Thanks for your patience.</h2>
				</section>

				<section>
					<h2>Copyright Note</h2>
					<p>The video clips in this presentation from the films Moon, Star Trek: The Voyage Home, Her, Star Trek, and 2001: A Space Odyssey belong to their respective copyright holders and are used here without permission.</p>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: false,
				progress: true,
				history: true,
				center: true,

				transition: 'none', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>
		<script src="js/microphone/microphone.min.js"></script>
		<script src="js/custom.js"></script>

	</body>
</html>
